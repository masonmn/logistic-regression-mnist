{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "In this exercise you will implement the logistic regression algorithm and use your code to learn to classify images of digits from the MNIST dataset. The MNIST database is a large database of handwritten digits that is commonly used for training and testing in the field of machine learning. Here are some sample images from the dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"mnist_sample.png\", height=\"200\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Load the Data\n",
    "\n",
    "Using the np.loadtxt() function, import all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\"\"\"\n",
    "    For digits 5 vs. 8, use the datasets starts with 58***.gz\n",
    "\"\"\"\n",
    "\n",
    "training_images = np.loadtxt(\"58Train_Images.gz\")\n",
    "labels = np.loadtxt(\"58Train_Labels.gz\")\n",
    "test_images = np.loadtxt(\"58Test_Images.gz\")\n",
    "test_labels = np.loadtxt(\"58Test_Labels.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Initialize w and b using a normal distribution N ~ (0, 0.1).\n",
    "Note: we do not pre-pend 1 in our data. b represent w0 in our slides.\n",
    "Set Learning rate L = 0.01.\n",
    "Set numImages, numTestingImages to the number of training and test images respectively.\n",
    "\n",
    "Initialized variables are global.\n",
    "\"\"\"\n",
    "w = np.random.normal(0, math.sqrt(0.1), training_images.shape[1])\n",
    "b = np.random.normal(0, math.sqrt(0.1), 1)\n",
    "L = 0.01\n",
    "numImages = training_images.shape[0]\n",
    "numTestingImages = test_images.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(v):\n",
    "    return 1 / (1 + np.exp(-v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax\n",
    "Implement the softmax activation function below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(v):\n",
    "    \"\"\"Returns the softmax of a vector v\n",
    "    \n",
    "    Input:\n",
    "    - v: a vector that needs to be normalized\n",
    "    \n",
    "    Output:\n",
    "    A vector whose entries have been normalized according to the softmax activation function.\n",
    "    \"\"\"\n",
    "    e_v = np.exp(v - np.max(v))\n",
    "    return e_v / e_v.sum(axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Gradient Descent\n",
    "Write a procedure that updates w and b with a gradient descent step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(imags, labels, w, b):\n",
    "    \"\"\"Updates the parameters w and b according to the gradient descent algorithm in our slides\n",
    "       Note: b is w0 in our slides\n",
    "    \n",
    "    Inputs:\n",
    "    - imags:  Batch of images\n",
    "              Note: Each image is in the form of a (1 x 784) list of normalized pixel values)\n",
    "    - labels: Batch of labels\n",
    "              Note: Each label is a one-hot vectors corresponding to the correct answer ([0,1] for one class \n",
    "                                                                                     and [1,0] for the other)\n",
    "    \n",
    "    Output:\n",
    "    None\n",
    "    \"\"\"\n",
    "    iteration = 300\n",
    "    eps = 0.0001\n",
    "    iteration_count = 0\n",
    "    while True:\n",
    "        iteration_count = iteration_count + 1\n",
    "        gradient = np.zeros_like(w)\n",
    "        for img, label in zip(training_images, labels):\n",
    "            binary_label = label[1] # get binary label form one-hot label. If one-hot label is [0, 1], it means\n",
    "                                    # the data sample has label 1. If one-hot label is [1, 0], it means label 0\n",
    "                                    # one-hot[1] will always give you the one dimension binary label.\n",
    "            posteriori = sigmoid(np.dot(img, w) + b) # this is (P(yi = 1 | xi))\n",
    "            b -= (posteriori - binary_label)/numImages\n",
    "            gradient = gradient + img*(posteriori - binary_label)\n",
    "        w -= L*gradient/numImages\n",
    "        if (iteration_count == iteration) or (np.linalg.norm(gradient) < eps):\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "We will now write a function that returns True if our network produced a correct answer, and false otherwise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(imag, label):\n",
    "    \"\"\"Returns True if our model predicts the correct answer\n",
    "    \n",
    "    Inputs:\n",
    "    - imag: An image in the form of a (1 x 784) list of pixel values\n",
    "    - label: A one-hot vector corresponding to the correct answer ([0,1] for one class and [1,0] for the other)\n",
    "    \n",
    "    Outputs:\n",
    "    A boolean representing whether the network succesfully predicted the correct class.\n",
    "    \"\"\"\n",
    "    posteriori = sigmoid(np.dot(imag, w))\n",
    "    if posteriori >= 0.5:\n",
    "        if label[1] == 1:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        if label[1] == 1:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Network and Testing our Results\n",
    "Now that we have all these functions at our disposal, let's train our network and see how it does!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.6171453822359699\n",
      "Testing Accuracy: 0.6237942122186495\n"
     ]
    }
   ],
   "source": [
    "# Training the network\n",
    "train_batch(training_images, labels, w, b)\n",
    "    \n",
    "correct = 0  # Number of correct predictions the network makes\n",
    "\n",
    "# Test Accuracy\n",
    "for i in range(numTestingImages):\n",
    "    if predict(test_images[i], test_labels[i]):\n",
    "        correct += 1\n",
    "\n",
    "# Train Accuracy\n",
    "train_correct = 0\n",
    "for i in range(numImages):\n",
    "    if predict(training_images[i], labels[i]):\n",
    "        train_correct += 1\n",
    "\n",
    "print(\"Training Accuracy: \" + str(float(train_correct) / len(training_images)))\n",
    "print(\"Testing Accuracy: \" + str(float(correct) / len(test_images)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try the same with the other data. Notice how the network performs much better when asked to classify 1s and 0s compared to the task of classifying 8s and 5s. Later we will find a way to improve our performance with 8s and 5s using tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
